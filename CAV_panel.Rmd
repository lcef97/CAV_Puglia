---
title: "Exploratory analysis of accesses to support centers for gender-based violence
  in Apulia"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning= FALSE)
par(mar = c(2,2,1,1))
library(magrittr)
library(sf)
library(INLA)
#if(!rlang::is_installed("pscl")) install.packages("pscl")
```

## Data

The dataset employed regards the counts of accesses to gender-based violence support centers in the Apulia region by residence municipality of the women victims of violence in 2021-2024. `R` codes to generate the dataset are in the R script [posted here](https://github.com/lcef97/CAV_Puglia/blob/main/CAV_full.R) which this report is based on. 

Here, we only take into account the violence reports which support centers actually take charge of, at the risk of underestimating the counts of gender-based violence cases.
This choice is driven by the need of avoiding duplicated records, since e.g. it may happen that a support center redirects a victim to another support center. 
```{r input mute, echo = FALSE, message = FALSE, warning = FALSE, output = FALSE}

## Input ----------------------------------------------------------------------#
 
load("input/CAV_input_mun_2021.RData")
load("input/CAV_input_mun_2022.RData")
load("input/CAV_input_mun_2023.RData")
load("input/CAV_input_mun_2024.RData")

source("Auxiliary/Functions.R")

CAV_mun_21 <- CAV_mun_21 %>% dplyr::rename(N_ACC_2021 = .data$N_ACC)
CAV_mun_22 <- CAV_mun_22 %>% dplyr::rename(N_ACC_2022 = .data$N_ACC)
CAV_mun_23 <- CAV_mun_23 %>% dplyr::rename(N_ACC_2023 = .data$N_ACC)
CAV_mun_24 <- CAV_mun_24 %>% dplyr::rename(N_ACC_2024 = .data$N_ACC)

load("input/Shp.RData")

#'  Function to extract numeric digits from a strings vector (needed to filter age):
nn_extract <- function(string){
  nn <- gregexpr("([0-9])", string)
  ls.out <- regmatches(as.list(string), nn)
  res <- unlist(lapply(ls.out, function(x) as.numeric(paste(x, collapse = ""))))  
  return(res)
}

Popolazione_Puglia_2021 <- readr::read_csv("input/Popolazione_Puglia_2021.csv") %>% 
  dplyr::select(.data$ITTER107, .data$Territorio, .data$SEXISTAT1, .data$ETA1, .data$Value) %>% 
  dplyr::filter(.data$ETA1 != "TOTAL") %>% 
  dplyr::mutate(ETA1 = nn_extract(.data$ETA1)) %>% 
  dplyr::mutate(ITTER107 = as.numeric(.data$ITTER107))

Popolazione_Puglia_2022 <- readr::read_csv("input/Popolazione_Puglia_2022.csv") %>% 
  dplyr::select(.data$ITTER107, .data$Territorio, .data$SEXISTAT1, .data$ETA1, .data$Value) %>% 
  dplyr::filter(.data$ETA1 != "TOTAL") %>% 
  dplyr::mutate(ETA1 = nn_extract(.data$ETA1)) %>% 
  dplyr::mutate(ITTER107 = as.numeric(.data$ITTER107))

Popolazione_Puglia_2023 <- readr::read_csv("input/Popolazione_Puglia_2023.csv") %>% 
  dplyr::select(.data$ITTER107, .data$Territorio, .data$SEXISTAT1, .data$ETA1, .data$Value) %>% 
  dplyr::filter(.data$ETA1 != "TOTAL") %>% 
  dplyr::mutate(ETA1 = nn_extract(.data$ETA1)) %>% 
  dplyr::mutate(ITTER107 = as.numeric(.data$ITTER107))

Popolazione_Puglia_2024 <- readr::read_csv("input/Popolazione_Puglia_2024.csv",
                                           quote = "")  %>% 
  dplyr::filter(.data$AGE != "TOTAL") %>% 
  dplyr::mutate(ETA1 = nn_extract(.data$AGE)) %>% 
  dplyr::mutate(ITTER107 = as.numeric(.data$REF_AREA)) %>% 
  dplyr::rename(SEXISTAT1 = .data$SEX, Value = .data$Osservazione)%>% 
  dplyr::select(.data$ITTER107, .data$SEXISTAT1, .data$ETA1, .data$Value)


Pop_f_15 <- Popolazione_Puglia_2021 %>% 
  dplyr::left_join(Popolazione_Puglia_2022,
                   by = c("ITTER107", "Territorio", "SEXISTAT1", "ETA1")) %>% 
  dplyr::left_join(Popolazione_Puglia_2023,
                   by = c("ITTER107", "Territorio", "SEXISTAT1", "ETA1")) %>% 
  dplyr::left_join(Popolazione_Puglia_2024,
                   by =  c("ITTER107",  "SEXISTAT1", "ETA1"))

names(Pop_f_15) <-  c("PRO_COM", "Comune", "Sesso", "Eta", 
                      "Popolazione_21", "Popolazione_22", "Popolazione_23", "Popolazione_24")

Pop_f_15 <- Pop_f_15 %>% dplyr::filter(.data$Sesso == 2) %>% 
  dplyr::filter(.data$Eta > 14) %>% 
  dplyr::group_by(.data$PRO_COM, .data$Comune) %>% 
  dplyr::summarise(nn_2021 = sum(.data$Popolazione_21),
                   nn_2022 = sum(.data$Popolazione_22),
                   nn_2023 = sum(.data$Popolazione_23),
                   nn_2024 = sum(.data$Popolazione_24)) %>%
  dplyr::ungroup()


# Tremiti Islands are a singleton --> need to remove them to perform spatial analysis
suppressWarnings({
  singletons <- Shp$PRO_COM[which(
    unlist(lapply(spdep::poly2nb(Shp),
                  function(x) x[1L] == 0)))]
})

load("input/dists_th_22.RData")
load("input/dists_th_23.RData")
load("input/dists_th_24.RData")
names(dists_th_22)[2] <- names(dists_th_23)[2] <- names(dists_th_24)[2] <- "TEP_th"
distances <- rbind(dists_th_22, dists_th_22, dists_th_23, dists_th_24) %>% 
  dplyr::mutate(Year = c(rep(2021, nrow(dists_th_22)),
                         rep(2022, nrow(dists_th_22)),
                         rep(2023, nrow(dists_th_23)),
                         rep(2024, nrow(dists_th_24))) )


Shp_con <- dplyr::filter(Shp, !.data$PRO_COM %in% singletons)
n <- nrow(Shp_con)


dd <- Shp_con %>% dplyr::left_join(Pop_f_15[, -2], by = "PRO_COM") %>% 
  dplyr::left_join(dplyr::select(CAV_mun_21, -.data$comune),by = "PRO_COM") %>% 
  dplyr::left_join(dplyr::select(CAV_mun_22, -.data$comune),by = "PRO_COM") %>% 
  dplyr::left_join(dplyr::select(CAV_mun_23, -.data$comune),by = "PRO_COM") %>% 
  dplyr::left_join(dplyr::select(CAV_mun_24, -.data$comune),by = "PRO_COM") %>% 
  tidyr::pivot_longer(cols = tidyselect::starts_with("nn_") | 
                        tidyselect::starts_with("N_ACC_"),
                      names_to = c(".value", "Year"),
                      names_pattern = "(nn|N_ACC)_(\\d+)" ) %>% 
  dplyr::mutate(Year=as.numeric(.data$Year)) %>% 
  dplyr::left_join(dplyr::select(Indicators, -.data$Comune), by = "PRO_COM") %>% 
  dplyr::arrange(.data$Year, .data$PRO_COM)  %>% 
  dplyr::left_join(distances, by = c("PRO_COM", "Year")) %>% 
  dplyr::mutate(CAV = as.numeric(.data$TEP_th == 0)) %>% 
  dplyr::mutate(Y_2021 = as.numeric(.data$Year == 2021)) %>% 
  dplyr::mutate(Y_2022 = as.numeric(.data$Year == 2022)) %>% 
  dplyr::mutate(Y_2023 = as.numeric(.data$Year == 2023)) %>% 
  dplyr::mutate(Y_2024 = as.numeric(.data$Year == 2024)) %>% 
  dplyr::mutate(TEP_th = as.vector(scale(.data$TEP_th))) %>% 
  dplyr::mutate(AES = as.vector(scale(.data$AES))) %>% 
  dplyr::mutate(MFI = as.vector(scale(.data$MFI)))  %>% 
  dplyr::mutate(PDI = as.vector(scale(.data$PDI)))  %>% 
  dplyr::mutate(ELL = as.vector(scale(.data$ELL)))  %>% 
  dplyr::mutate(ER = as.vector(scale(.data$ER)))  %>% 
  dplyr::mutate(PGR = as.vector(scale(.data$PGR)))  %>% 
  dplyr::mutate(UIS = as.vector(scale(.data$UIS)))  %>% 
  dplyr::mutate(ELI = as.vector(scale(.data$ELI)))  %>% 
  #dplyr::select(-.data$Year) %>% 
  dplyr::mutate(ID = c(1:nrow(.))) %>% 
  dplyr::mutate(Area = as.numeric(as.factor(.data$PRO_COM)))



# Municipalities from which no woman reported violence --> count == 0
dd$N_ACC[is.na(dd$N_ACC)] <- 0

# "access ratio"
dd$LN_ACC <- log(dd$N_ACC/dd$nn)

#' neighbours list ------------------------------------------------------------#
nb_con <- spdep::poly2nb(dd[c(1:n), ])

#' neighbouring/adjacency matrix ----------------------------------------------#
W_con <- spdep::nb2mat(nb_con, style = "B")
rownames(W_con) <- colnames(W_con) <- dd$PRO_COM[c(1:n)]

#' Laplacian matrix -----------------------------------------------------------#
D_con <- Matrix::Diagonal(x=apply(W_con, MARGIN=1, FUN=function(x) sum(x)), n=n)
Lapl_con <- D_con - W_con
V_con <- eigen(Lapl_con)$vectors

constr <- INLA:::inla.bym.constr.internal(
  Q = Lapl_con, adjust.for.con.comp = T)
A_constr <- kronecker(Matrix::Diagonal(n=4,x=1), constr$constr$A)

#'  Necessary to constrain the BYM model --------------------------------------#
constr.BYM <- list(
  A = cbind(Matrix::Matrix(0, nrow = nrow(A_constr), ncol = ncol(A_constr)), A_constr),
  e=c(0,0,0,0) )


zhat_plot <- function(mod){
  n <- nrow(mod$.args$data)
  rr <- range(mod$summary.random$ID$mean[c(1:n)])
  
  plot_map <- purrr::map(unique(dd$Year), function (t){
  dd %>% dplyr::mutate(zhat = mod$summary.random$ID$mean[c(1:n)]) %>% 
    dplyr::filter(as.numeric(.data$Year) == t) %>% 
    ggplot2::ggplot() +
    ggplot2::geom_sf(ggplot2::aes(fill = .data$zhat))+
    ggplot2::labs(title = paste("Year:", t), 
                  fill = expression(E * "[" * z * "]")) +
    ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
    ggplot2::theme_classic()
  })

do.call(gridExtra::grid.arrange, c(plot_map, nrow = 2, ncol = 2))

}

yhat_plot <- function(mod ){
  
  yhat <- round(mod$summary.fitted.values$mean, 0)

  rr <- c(0, max(yhat))
  
  plot_map <- purrr::map(unique(dd$Year), function (t){
    dd %>% dplyr::mutate(yhat = yhat) %>% 
      dplyr::filter(as.numeric(.data$Year) == t) %>% 
      ggplot2::ggplot() +
      ggplot2::geom_sf(ggplot2::aes(fill = .data$yhat)) +
      ggplot2::labs(title = paste("Year:", t), 
                    fill = expression(E * "[" * hat(y) * "]") )+
      ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
      ggplot2::theme_classic()
  })
  do.call(gridExtra::grid.arrange, c(plot_map, nrow = 2, ncol = 2))
}

etahat_plot <- function(mod, predictor = FALSE){
  
  etahat <- mod$summary.linear.predictor$mean
  
  rr <- range(etahat)
  
  plot_map <- purrr::map(unique(dd$Year), function (t){
    dd %>% 
      dplyr::mutate(etahat = etahat) %>% 
      dplyr::filter(as.numeric(.data$Year) == t) %>% 
      ggplot2::ggplot() +
      ggplot2::geom_sf(ggplot2::aes(fill =  .data$etahat )) +
      ggplot2::labs(title = paste("Year:", 2020+ t),
                    fill = expression(E * "[" * eta * "]")) + 
      ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
      ggplot2::theme_classic()
    })

do.call(gridExtra::grid.arrange, c(plot_map, nrow = 2, ncol = 2))

}


```


In order to avoid singletons, i.e. municipalities with no neighbours, in the spatial structure of the dataset, the Tremiti Islands need to be removed from the list of municipalities included ($0$ accesses recorded so far).

Therefore, the municipality-level dataset in scope consists of $256$ areas. 

We can only take into account the accesses to support centers for which the origin municipality of victims is reported; therefore the total count of accesses in scope is $1477$, $1516$, $1822$ and $1778$for the reference years respectively:


Here, we plot the log-access rate per residence municipality, i.e. the logarithm of the ratio between access counts and female population. Blank areas correspond to municipalities from which zero women accessed support centers ($82$ municipalities).

```{r Log accesses plot, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Log-access rate" }


ggy21 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = dplyr::filter(dd, .data$Y_2021 == 1), 
                   ggplot2::aes(fill = .data$LN_ACC))+
  ggplot2::labs(fill = "Log-accesses, 2021")+
  ggplot2::scale_fill_viridis_c(na.value = "white",
                                direction = -1,
                                limits = c(-9.5, -4.5))+
  ggplot2::theme_classic()

ggy22 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = dplyr::filter(dd, .data$Y_2022 == 1), 
                   ggplot2::aes(fill = .data$LN_ACC))+
  ggplot2::labs(fill = "Log-accesses, 2022")+
  ggplot2::scale_fill_viridis_c(na.value = "white",
                                direction = -1,
                                limits = c(-9.5, -4.5))+
  ggplot2::theme_classic()

ggy23 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = dplyr::filter(dd, .data$Y_2023 == 1), 
                   ggplot2::aes(fill = .data$LN_ACC))+
  ggplot2::labs(fill = "Log-accesses, 2023")+
  ggplot2::scale_fill_viridis_c(na.value = "white",
                                direction = -1,
                                limits = c(-9.5, -4.5))+
  ggplot2::theme_classic()

ggy24 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = dplyr::filter(dd, .data$Y_2024 == 1), 
                   ggplot2::aes(fill = .data$LN_ACC))+
  ggplot2::labs(fill = "Log-accesses, 2024")+
  ggplot2::scale_fill_viridis_c(na.value = "white",
                                direction = -1,
                                limits = c(-9.5, -4.5))+
  ggplot2::theme_classic()

gridExtra::grid.arrange(ggy21, ggy22, ggy23, ggy24, nrow = 2, ncol = 2)

```

## Covariates

Our target is explaining the number of accesses to support centers, $y$, defined at the municipality level, on the basis of a set of candidate known variables. $y$ is modelled with simple Poisson regression.

We have at disposal a number of candidate explanatory variables, which include the distance of a municipality from the closest support center and a set of variables measuring social vulnerability under different dimensions; these latter covariates are provided by [the ISTAT](https://www.istat.it/comunicato-stampa/indice-di-fragilita-comunale-ifc/) and are among the components of the Municipality Frailty Index (MFI). A more detailed description of MFI components is in [this excel metadata file](https://github.com/lcef97/CAV_Puglia/blob/main/Metadata/Indice_composito_fragilita_PUGLIA_2021.xlsx).

All covariates are quantitative variables and to ease model interpretation are scaled to have null mean and unit variance.

  -  $\mathrm{TEP\_th}$, i.e. the distance of each municipality from the closest municipality hosting a support center. Distance is measured by road travel time in minutes (acronym TEP stays for Tempo Effettivo di Percorrenza, i.e. Actual Travel Time). Since to the best of our knowledge the list of active support centers changed between 2022 and 2023, we employ the list of centers active until 2022 for 2021-2022 data, and the list of centers active in 2023 for 2023 data.

  -  $\mathrm{AES}$, the distance from the closest infrastructural pole, always measured in travel time. Infrastructural poles are defined as municipalities or clusters of neighbouring municipalities provided with a certain endowment in health, education and transport infrastructure (more details can be found, e.g., [here](https://www.istat.it/comunicato-stampa/la-geografia-delle-aree-interne-nel-2020-vasti-territori-tra-potenzialita-e-debolezze/)).
  -  $\mathrm{MFI}$, i.e. the decile of municipality frailty index.
  -  $\mathrm{PDI}$, i.e. the dependency index, i.e. population either $\leq 20$ or $\geq 65$ years over population in $[20 - 64]$ years.
  -  $\mathrm{ELL}$, i.e. the proportion of people aged $[25-54]$ with low education.
  -  $\mathrm{ERR}$, i.e. employment rate among people aged $[20-64]$.
  -  $\mathrm{PGR}$, i.e. population growth rate with respect to 2011.
  -  $\mathrm{UIS}$, i.e. the ventile of the density of local units of industry and services (where density is defined as the ratio between the counts of industrial units and population).
  -  $\mathrm{ELI}$, i.e. the ventile of employees in low productivity local units by sector for industry and services.

First, we visualise the correlations among these explanatory variables:

```{r correls, echo = F, warning = F, fig.height = 3, fig.cap = "Correlations in explanatory variables"}
glm_all_X <- glm(N_ACC ~ 1 + TEP_th + MFI + AES + PDI + ELL + ER +
                   PGR + UIS + ELI + offset(log(nn)),
                 data = dd, family = "poisson")
# model matrix
X <- model.matrix(glm_all_X)



ggplot2::ggplot(data = reshape2::melt(cor(X[,-1]))) +
  ggplot2::geom_tile(ggplot2::aes(
    x = .data$Var2, y = .data$Var1, fill = .data$value), color = "black", size = 3) +
  ggplot2::geom_text(ggplot2::aes(
    x = .data$Var2, y = .data$Var1, label = round(.data$value, 2))) +
  ggplot2::scale_fill_gradient2(
    low = "blue", mid = "white", high = "red", midpoint = 0) +
  ggplot2::theme_minimal()
```

We see the correlation between the two distances is very high ($0.72$), and so is the correlation between the fragility index decile and the density of productive units. 

In the first case, we drop the distance from the nearest infrastructural pole. In the latter we drop `MFI`, which is a combination of all covariates except for `TEP_th`, and is a weakly informative choice.


## Nonspatial regression

We regress the counts of accesses $y$ to support centers on the aforementioned explanatory variables. To interpret regression coefficients in an easier way, all covariates are scaled to zero mean an unit variance. 

\begin{equation}
y_{it} \mid \eta_{it} \sim \mathrm{Poisson}(E_{it} \, e^{\eta_{it}}) \quad \text{where} \quad
\eta_{it} = X_{it}^{\top} \beta
\label{eq:glm}
\end{equation}

Where $X$ are the covariates defined earlier, $\beta$ are covariate effects, and $E_{it}$ is the female population aged $\geq 15$ in municipality $i$ and year $t$.

To gain more insight on the role of all explanatory variables we show the posterior summaries of the regression model; the posterior distribution is approximated with the INLA [@INLAVB].
 

 

```{r INLA nosp, warning = FALSE, echo = FALSE, message = FALSE, results = "asis"}

cav_glm <- glm(N_ACC ~ 0 + Y_2021 + Y_2022 + Y_2023 + Y_2024 + 
                 TEP_th + PDI + ELL + ER +
                   PGR + UIS + ELI + offset(log(nn)),
                 data = dd, family = "poisson")

cav_nosp_inla <- inla(
  N_ACC ~0 + Y_2021 + Y_2022 +Y_2023 +Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER  ,
  offset = log(nn),
  family = "poisson", data =dd,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)

betas.nosp.inla <-  cav_nosp_inla$summary.fixed %>% 
  dplyr::select(c(1,2,3,5)) %>% 
  dplyr::mutate(Effect = c("Int_2021", "Int_2022", "Int_2023", "Int_2024",
                           rownames(cav_nosp_inla$summary.fixed)[-c(1:4)])) %>% 
  dplyr::relocate(.data$Effect, .before = 1) %>%  
  dplyr::rename(Mean = .data$mean, Sd = .data$sd)
  

print(xtable::xtable(betas.nosp.inla, digits = 3), include.rowname  = F)

```



  - `TEP_th`: The distance from the closest support center appears to play an important role. The easiest interpretation is that the physical distance represents a barrier to violence reporting. This is quite intuitive if we think of the material dynamics of reporting gender-based violence: one could reasonably expect violent men to prevent their partners to take a long rout and come out to report the violence suffered.
  
  - `ELI`: The (ventile of the distribution of the) share of employees in low productivity economic units is a clear indicator of (relative) economic underdevelopment. The most naive interpretation would be that in underdeveloped areas reporting gender violence is somewhat harder than in developed ones.

  - `PGR`: The association with population growth rate does not appear to be significantly different from zero.
  
  <!-- is harder to interpret. This association is most likely influenced by several demographic instrumental variables we are not keeping into account and would indeed deserve a more dedicated focus. --> 
  
  - `UIS`: The (ventile of the distribution of the) density of production units appears to have a positive association with VAW reporting, though it is not very high in absolute value if compared to coariates such as `TEP_th`.

  - `ELL`: The association with the proportion of people with low educational level has negative sign and is high in absolute value. The interpretation seems quite easy: cultural development, in general, would encourage reporting violence.
  
  - `PDI`: The association with population dependency index is negative, and its interpretation is ambiguous as well since the proportion of old or very young people can be read as a limiting factor both for VAW incidence and reporting.
  
  - `ER`: The association with employment rate is very strong and bears negative sign for 2021 and 2023 data.

## Spatial regression

#### Exploratory analysis of residuals
We plot the log-residuals $\varepsilon$ of the nonspatial regression models, defined as $\varepsilon := \ln y_{it} - \ln \hat{y}_{it}$ being $\hat{y}_{it}$ the fitted value.

```{r glm residuals, echo = FALSE, warnings = FALSE, message = FALSE, output = FALSE}
#L_block <- kronecker(diag(1, 3), Lapl_con)
constr <- INLA:::inla.bym.constr.internal(Lapl_con, adjust.for.con.comp = T)
A_constr <- kronecker(Matrix::Diagonal(x=1, n=4), constr$constr$A)
resids_glm <- resids_nosp <- log(dd$N_ACC) - log(cav_nosp_inla$summary.fitted.values$mean)


rr <- range(resids_glm[which(is.finite(resids_glm))])

ggr21 <- dd %>% 
  dplyr::mutate(log_resids_2021 = resids_glm) %>% 
  dplyr::filter(.data$Y_2021 == 1) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(ggplot2::aes(fill = .data$log_resids_2021))+
  ggplot2::labs("blank") +
  ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
  ggplot2::theme_classic()

ggr22 <- dd %>% 
  dplyr::mutate(log_resids_2022 = resids_glm) %>% 
  dplyr::filter(.data$Y_2022 == 1) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(ggplot2::aes(fill = .data$log_resids_2022))+
  ggplot2::labs("blank") +
  ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
  ggplot2::theme_classic()

ggr23 <- dd  %>% 
  dplyr::mutate(log_resids_2023 = resids_glm) %>% 
  dplyr::filter(.data$Y_2023 == 1) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(ggplot2::aes(fill = .data$log_resids_2023))+
  ggplot2::labs("blank") +
  ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
  ggplot2::theme_classic()

ggr24 <- dd  %>% 
  dplyr::mutate(log_resids_2024 = resids_glm) %>% 
  dplyr::filter(.data$Y_2024 == 1) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(ggplot2::aes(fill = .data$log_resids_2024))+
  ggplot2::labs("blank") +
  ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1, limits = rr) +
  ggplot2::theme_classic()

#' Problem: cannot apply Moran test to infinite values!
#' Hence we need to only test autocorrelation across nonzero records.
#' This strongly limits the relevance of the test, if I have a better idea I'll implememnt it.
nonzero_21 <- which(dd$N_ACC > 0 & dd$Y_2021 == 1)
nonzero_22 <- which(dd$N_ACC > 0 & dd$Y_2022 == 1)
nonzero_23 <- which(dd$N_ACC > 0 & dd$Y_2023 == 1)
nonzero_24 <- which(dd$N_ACC > 0 & dd$Y_2024 == 1)


spdep::set.ZeroPolicyOption(TRUE)
suppressWarnings(nb_nonzero_21 <- spdep::poly2nb(dd[nonzero_21, ]))
suppressWarnings(nb_nonzero_22 <- spdep::poly2nb(dd[nonzero_22, ]))
suppressWarnings(nb_nonzero_23 <- spdep::poly2nb(dd[nonzero_23, ]))
suppressWarnings(nb_nonzero_24 <- spdep::poly2nb(dd[nonzero_24, ]))


nonzero_singletons_21 <- which(unlist(lapply(nb_nonzero_21, function(X) X[1L]==0)))
nonzero_singletons_22 <- which(unlist(lapply(nb_nonzero_22, function(X) X[1L]==0)))
nonzero_singletons_23 <- which(unlist(lapply(nb_nonzero_23, function(X) X[1L]==0)))
nonzero_singletons_24 <- which(unlist(lapply(nb_nonzero_24, function(X) X[1L]==0)))


if(length(nonzero_singletons_21 > 0)){
  nonzero_con_21 <- nonzero_21[-nonzero_singletons_21]
  } else nonzero_con_21 <- nonzero_21
nonzero_con_22 <- nonzero_22[-nonzero_singletons_22]
nonzero_con_23 <- nonzero_23[-nonzero_singletons_23]
if(length(nonzero_singletons_24 > 0)){
  nonzero_con_24 <- nonzero_24[-nonzero_singletons_24]
  } else nonzero_con_24 <- nonzero_24

nb_con_nonzero_21 <- spdep::poly2nb(dd[nonzero_con_21, ])
nb_con_nonzero_22 <- spdep::poly2nb(dd[nonzero_con_22, ])
nb_con_nonzero_23 <- spdep::poly2nb(dd[nonzero_con_23, ])
nb_con_nonzero_24 <- spdep::poly2nb(dd[nonzero_con_24, ])



```
```{r Log residuals, echo=FALSE, fig.cap = "Log-residuals in GLM regression", message=FALSE, warning=FALSE}

gridExtra::grid.arrange(ggr21, ggr22, ggr23, ggr24, nrow = 2, ncol = 2)


```


Residuals may exhibit spatial structure. To assess it, we employ the Moran and Geary tests. Since 

Please notice that log-residuals only take finite values across the municipalities whose female citizens have reported at least one case of violence.


Additionally, this set of municipalities may include some singletons, which we remove to assess the value of the Moran and Geary statistics. Thus, for each year we have defined the indexes set `nonzero_con` as the set of municipalities from which at least one case of gender-based violence has been reported, *and* which have at least one neighbouring municipality from which at least one case of gender-based violence was reported as well. For brevity, we only show the standardised $I$ values, which under the null hypothesis should be distributed as $N(0,1)$. The Geary's test is also included for completeness.

```{r moran residuals, echo = F, message = F, warning = F, results = "asis"}

autocorrel.tests <- as.data.frame(
  do.call(rbind,  lapply(list(nonzero_con_21, nonzero_con_22, 
                              nonzero_con_23, nonzero_con_24), function(NN){
    rbind(
      round(unlist(spdep::moran.test(resids_glm[NN],
                                     listw = spdep::nb2listw( 
                                       spdep::poly2nb(dd[NN, ])))[c("statistic", "p.value")]), 3),
      round(unlist(spdep::geary.test(resids_glm[NN],
                                     listw = spdep::nb2listw(
                                       spdep::poly2nb(dd[NN, ])))[c("statistic", "p.value")]), 3))
               }))) %>% 
  dplyr::mutate(test = rep(c("Moran", "Geary"), 4)) %>% 
  dplyr::mutate(year = rep(c("2021", "2022", "2023", "2024"), each = 2)) %>% 
  dplyr::select(c(4,3,1,2))
names(autocorrel.tests) <- c("Year", "Test", "Statistic_std", "p.value")

print(xtable::xtable(autocorrel.tests), include.rowname = F, n.digits = 3)                 
               
```

We find evidence for spatial autocorrelation. However, we must stress out that this result does not refer to all the regional territory, but only to a subset of all municipalities.

Based on the autocorrelation evidence, though it has only been assessed for a subset of all municipalities, we try implementing some simple spatial models by adding a conditionally autoregressive latent effect, say $z$, to the linear predictor

\begin{equation}
\eta_{it} = X_{it}^{\top} \beta + z_{it} 
\label{eq:mspat}
\end{equation}


We test a total of four models, all of which have a prior distribution depending on the spatial structure of the underlying graph, in this case the Apulia region. 

In the following, the area-specific latent field is denoted as $z_i = (z_{i, 2021} \, z_{i, 2022} \, z_{i, 2023}, z_{i, 2024} )^{\top}$

We describe the spatial structure starting from municipalities neighbourhood, and introduce the neighbourhood matrix $W$, whose generic element $w_{ij}$ takes value $1$ if municipalities $i$ and $j$ are neighbours and $0$ otherwise. For each $i \in [1,n]$, $d_i:= \sum_{j=1}^n w_{ij}$ is the number of neigbours of $i$-th municipality. Please notice we have have $n = 256$.

For all models, we define $\Sigma$ as the covariance matrix of the latent effect $z$; its off-diagonal entries describe dependence in $z$ between different years. 
Spatial models are computed by approximating the marginal posteriors of interest via the Integrated Nested Laplace Approximation (INLA), adopting the novel Variational Bayes Approach [@INLAVB].
Before proceeding with model structure, we need a short digression on how `R-INLA` works. The INLA framework is hierarchical and is based on a distinction between latent Gaussian fields (GFs) and hyperparameters. In our case, the former include intercepts, covariate effects and the spatial latent field. In the INLA literature latent Gaussian fields are frequently labelled as $x$ but we avoid doing so in order not to introduce notation ambiguity with respect to covariates. Hyperparameters in our case coincide with the parameters of $z$. Then, it is necessary to approximate the posterior distribution of both hyperparameters and latent GFs.  
INLA follows a framework of numerical integration over a grid of hyperparameters, which is centered at the mode. Locating the posterior mode of hyperparameters is thus the first, crucial task to approximate all posterior distributions involved in the model. `R-INLA` employs an exploration strategy over the whole real axis [@INLA]. For this reason, hyperparameters need be re-parametrised in such a way to be defined over all $\mathbb{R}$, and the priors are thus actually written on the so-called internal scale of hyperparameters. This approach may be hiding a trick if specifical constraints are required on hyperparameters. For instance, $\Sigma$ needs to be positive-definite and symmetric. If the hyperparameter exploration is carried out on the whole real axis, nothing ensures, in principle, that the values of the single entries in $\Sigma$ ensure it is positive definite. For instance, consider the case the hyperparameter exploration procedure comes across this correlation matrix
$$
\Sigma_{\mathrm{ND}} =
\begin{pmatrix}
1 & 0.4 & 0.9\\
0.4 & 1 & -0.4\\
0.9 & -0.4 & 1
\end{pmatrix}
$$

It can be seen that $\Sigma_{\mathrm{ND}}$ has one negative eigenvalue, and is thus indefinite: it cannot be a valid correlation matrix and would cause trouble if, e.g., the covariance matrix is assigned a Wishart prior. A trivial solution is to define the correlation matrix as a quadratic form, say $\Sigma := B B^\top$, and setting a prior distribution on $B$. Of course, it is convenient to define triangular $B$ matrix - otherwise, both a high number of parameters would be required, and the prior on $\Sigma$ could not be calculated (could it?) starting from the prior on $B$ as the Jacobian matrix would \textit{not} be squared. 


Priors for spatial effects and hyperparameters are defined in [this R script](https://github.com/lcef97/CAV_Puglia/blob/main/Auxiliary/Functions.R). The general structure follows the framework of the `bigDM` R package [@vicente2023high].


#### ICAR model

The Intrinsic CAR model is the simplest formulation among spatial autoregressive models. The conditional distribution of each value $z_i \mid z_{-i}$ is:

\begin{equation}
z_i \mid z_{-i} \sim \mathcal{N} \left( \sum_{j=1}^n \frac{w_{ij}}{d_i} z_j \,, \frac{1}{d_i} \Lambda^{-1} \right)
\label{eq:icar_loc}
\end{equation}

And the joint prior distribution is:

\begin{equation}
z \mid \Sigma \sim \mathcal{N} \left( 0, \Sigma \otimes (D - W)^{+} \right)
\label{eq:icar_joint}
\end{equation}

Where $z$ is a $256 \times 4$ matrix. Since the joint distribution of $z$ is improper, a sum-to-zero constraint, i.e. $\sum_{i=1}^n z_{it} = 0$ for $t = 2021, 2022, 2023, 2024$ is required for identifiability.


```{r inla icar, echo = FALSE, message = FALSE, warning = FALSE}

cav_IMCAR_inla <- inla(
  N_ACC ~ 0 + Y_2021 + Y_2022 + Y_2023 + Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.IMCAR.Bartlett(k = 4, W = W_con, df=6), 
      extraconstr = list(A = A_constr, e = c(0,0,0,0))),
  offset = log(nn), family = "poisson", data =dd,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)

#' summary, just for a check
#vcov_summary(cav_IMCAR_inla)
```

#### PCAR model

The intrinsic autoregressive model is relatively simple to interpret and to implement, 
while also requiring the minimum number of additional parameters (either the scale or the precision).


The drawback, however, is that we implicitly assume a deterministic spatial autocorrelation coefficient equal to 1.
When the autocorrelation is weak, setting an ICAR prior may be a form of misspecification.

A generalisation of this model is the PCAR (proper CAR), which introduces an autocorrelation parameter $\rho$. We assign a penalised complexity (PC) prior to $\rho$, and, following the thumb-rule proposed by [@PC] and [@BYM2] for the Besag-York-Mollié model (see after) we assume \textit{a priori} that $\pi (\rho \leq \frac{1}{2}) = \frac{2}{3}$.

\begin{equation}
z_i \mid z_{-i} \sim \mathcal{N} \left( \sum_{j=1}^n \rho \frac{w_{ij}}{d_i} z_j \,, \frac{1}{d_i} \Lambda^{-1}\right)
\label{eq:pcar_loc}
\end{equation}


```{r pcar run, message = FALSE, echo = FALSE, output = FALSE}

cav_PMCAR_inla <- inla(
  N_ACC ~  0+ Y_2021 + Y_2022 + Y_2023 + Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.PMCAR.Bartlett(k = 4, W = W_con, df = 4, PC = T)),
  offset = log(nn), control.inla = list(stupid.search = F),
  family = "poisson", data =dd, safe = F,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)

```

We show the posterior summary for the autocorrelation coefficient, obtained with the data at hand. 

```{r rho pcar, echo = FALSE, fig.height = 3, fig.cap = "Posterior marginal of the PCAR autocorrelation parameter"}
rho_marg_pcar <- inla.tmarginal(
  fun = function(X) 1/(1 + exp(-X)),
  marginal = cav_PMCAR_inla$marginals.hyperpar[[1]])

plot(rho_marg_pcar, type = 'l', xlab = expression(rho), ylab = expression(pi (rho ~ "|" ~ y)  ))

unlist(inla.zmarginal(rho_marg_pcar, silent = TRUE))
```
 
 The credible interval for $\rho$ is quite pushed towards unity, denoting the model estimates a strong spatial autocorrelation. 



#### Leroux model

As an alternative to take into account both structured and unstructured latent effects, we also test the Leroux autoregressive model [@Leroux]; throughout this report, this model will be referred to as the LCAR. In this case, the local prior for $z_i$ is

\begin{equation}
z_i \mid z_{-i} \sim \mathcal{N} \left( \sum_{j=1}^n \frac{\xi w_{ij}}{1 - \xi + \xi d_i}   z_j \,, \Lambda^{-1} \frac{1}{1 - \xi + \xi d_i}\right)
\label{eq:leroux_loc}
\end{equation}

Where $\xi \in [0, 1]$ is labelled as the mixing parameter. A more interesting representation of the Leroux model is the joint prior
$$
z \mid \Lambda, \xi \sim \mathcal{N}(0, [ \Lambda \otimes (\xi L + (1-\xi)I)]^{-1})
$$
where $L := D-W$ is the graph Laplacian matrix, $W$ is the neighbourhood matrix and $D$ is the corresponding degree matrix. We can clearly see how the mixing parameter allocates variability between two precision components, i.e. the Laplacian matrix for the spatial part and the the identity matrix for the noise.

The drawback of this model is the scarce interpretability with respect to more sophisticated ones like the BYM.


```{r INLA Leroux, echo = FALSE, message = FALSE}

cav_LMCAR_inla <- inla(
  N_ACC ~  0+ Y_2021 + Y_2022 + Y_2023 + Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.LMCAR.Bartlett(k = 4, W = W_con, df = 6, PC = T)),
  offset = log(nn), control.inla = list(stupid.search = F),
  family = "poisson", data =dd, safe = F,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)

```

#### BYM model


Another popular model to control for both spatial autocorrelation and random noise is the Besag, York and Mollié model. 
We employ a simplified formulation, with a unique mixing parameter for all three years. Under this model the latent effect is defined as: 

\begin{equation}
z = \sqrt{\phi} u M + \sqrt{1-\phi} v M
\label{eq:bym}
\end{equation}



Where: 

  - $u \sim \mathcal{N}(0, I_p \otimes L_\mathrm{scaled})$ is an independent multivariate ICAR process whose precision matrix is scaled in order that the geometric mean of marginal variances (i.e. the diagonal entries of $L^{+}$) is one
  - $v \sim \mathcal{N}(0, I_p \otimes I_n)$ is a Standard Normal variable
  - $M$ is a positive definite matrix such that $M'M = \Lambda^{-1}$. It is not necessarily the Cholesky factor of the scale parameter; in fact, a convenient but not unique way to define it may be $M = D^{-\frac{1}{2}}E^{\top}$ where $E$ and $D$ are the eigenvector and eigenvalues matrices of $\Lambda$ [@Urdangarin]. 

  - $\phi \in [0,1]$ is the mixing parameter.
  
Please notice that in the case of our data, $p=3$ and $n = 256$.
We assign a Uniform prior on $\phi$ (but the PC-prior would be a more rigorous choice) and the usual Wishart prior to $\Lambda$.

The BYM model features a variance mixing parameter, whose interpretation is eased by allowing to scale the ICAR and IID components. 


```{r BYM, echo = FALSE,   warning = FALSE, message = FALSE, output = FALSE}

cav_MBYM_inla <- inla(
  N_ACC ~ 0 + Y_2021 + Y_2022 + Y_2023 + Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.MBYM.Bartlett(k = 4, W = W_con, df = 6, PC = T ),
      extraconstr = constr.BYM) ,
  offset = log(nn),
  family = "poisson", data =dd,
  control.inla = list(stupid.search = FALSE), safe = FALSE,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)


```



We briefly compare the three models in scope through the WAIC [@GelmanWAIC]:

```{r WAICs table, echo = F, results = "asis", message = FALSE}

WAICS <- tibble::tibble(
  Model = c("Null", "ICAR", "PCAR", "Leroux", "BYM"),
  WAIC = round(c(
    cav_nosp_inla$waic$waic,  cav_IMCAR_inla$waic$waic,  cav_PMCAR_inla$waic$waic, 
    cav_LMCAR_inla$waic$waic, cav_MBYM_inla$waic$waic),3),
  Eff_params = round(c(
    cav_nosp_inla$waic$p.eff,   cav_IMCAR_inla$waic$p.eff,  cav_PMCAR_inla$waic$p.eff,
     cav_LMCAR_inla$waic$p.eff, cav_MBYM_inla$waic$p.eff),3))

print(xtable::xtable(WAICS, digits = 3),include.rowname = F)

```

As we can see, adding a spatial model is an improving element, not a waste of complexity.

Here we show some posterior summaries for $\beta$ under the BYM model.

```{r betas bym, echo = FALSE, results = "asis", message = FALSE}
betas.MBYM.inla   <- cav_MBYM_inla$summary.fixed %>% 
  dplyr::select(.data$mean, .data$sd, .data$`0.025quant`, .data$`0.975quant`) %>%   
  dplyr::rename(Mean = .data$mean, Sd = .data$sd,
                Q_0.025 = .data$`0.025quant`, Q_0.975 = .data$`0.975quant`)


print(xtable::xtable(betas.MBYM.inla, digits = 3), include.rowname = FALSE)

```


Estimations of $\beta$ differ slightly from the nonspatial model and credibility intervals are generally wider due to increased uncertainty. 

  - `TEP_th` The effect of the distance from the closest support center remains similar in mean and the interpretation is not altered.

  - `ELI`: The effect of the incidence of low-productivity economic units is utterly negligible

  - `PGR`: The association with population growth rate is positive as in the nonspatial model, though it is lesser in absolute value
  
  - `UIS`: The association with the density of productive units is positive and double, on average, with respect to the nonspatial model. Interpreting this association is complex, as it bears opposite sign with the employment rate, which should be another indicator of economic development.
  
  - `ELL`: The association with the incidence of low education levels, is even higher in mean than under the nonspatial model. We interpret this result as a strong *potential* impact of education on the chance that gender violence is reported.
  
  - `PDI`: The effect of structural dependency index is utterly negligible, as for the nonspatial model. 
  
  - `ER`: The effect associated with employment rate is negative and relatively high in absolute value. How to interpret this finding? Employment rate is clearly an indicator of economic development, hence the easiest interpretation is that in more developed areas there is a higher chance that gender violence is reported.


We show the expected latent effects:


```{r zhat mbym, echo = FALSE, message = FALSE, warning = FALSE, output = FALSE, fig.cap = "Estimated BYM latent effect"}

zhat_plot(cav_MBYM_inla)

```

We additionally show the fitted values of the counts of accesses, rounded to the closest integer.


```{r yhat mbym, echo = FALSE, message = FALSE, warning = FALSE, output = FALSE, fig.cap = "Fitted access counts, BYM model"}

yhat_plot(cav_MBYM_inla)

```

We show the posterior median of the marginal variances of $z$, i.e. the diagonal entries of $\Sigma$:

```{r Sigma BYM, echo = FALSE, message = FALSE, warning = FALSE}
vcov.BYM <- vcov_summary(cav_MBYM_inla)

Sigma_diag_df <- as.data.frame(vcov.BYM$var) %>% 
  dplyr::mutate(Year = c("2021", "2022", "2023", "2024")) %>% 
  dplyr::relocate(.data$Year, .before = 1)
names(Sigma_diag_df)[-1] <- c("Mean", "Sd", "Q0.025", "Median", "Q0.975")

print(xtable::xtable(Sigma_diag_df, digits = 3), include.rowname = F)
```


For more insight on the dependence structure between the three years, posterior summaries for correlations are shown in the following. In terms of point estimates, the only high correlation appears that of 2021-2022.


```{r correlations, message = FALSE, warning = FALSE, echo = FALSE, results = "asis"}
cov_df <- as.data.frame(vcov.BYM$cor) %>% 
  dplyr::mutate(Years = c("2021-22", "2021-23", "2021-24",
                          "2022-23", "2022-24", "2023-24")) %>% 
  dplyr::relocate(.data$Years, .before = 1)
names(cov_df)[-1] <- c("Mean", "Sd", "Q0.025", "Median", "Q0.975")

print(xtable::xtable(cov_df, digits = 3), include.rowname = F)
```

  
Lastly, we have a look at the mixing parameter under the Leroux and BYM models.

```{r mixing leroux, echo = FALSE, fig.height = 3, fig.cap = "Posterior marginal of the LCAR mixing parameter"}
xi_marg_lcar <- inla.tmarginal(
  fun = function(X) 1/(1 + exp(-X)),
  marginal = cav_LMCAR_inla$marginals.hyperpar[[1]])

plot(xi_marg_lcar, type = 'l', xlab = expression(xi), ylab = expression(pi (xi ~ "|" ~ y)  ))

unlist(inla.zmarginal(xi_marg_lcar, silent = TRUE))
```

As we see, the Leroux mixing parameter is not particularly high, but interpreting it properly is hampered by the difficulty in scaling the precision matrix, which is a drawback of non-intrinsic models. 

```{r mixing bym, echo = FALSE, fig.height = 3, fig.cap = "Posterior marginal of the BYM mixing parameter"}
phi_marg_bym <- inla.tmarginal(
  fun = function(X) 1/(1 + exp(-X)),
  marginal = cav_MBYM_inla$marginals.hyperpar[[1]])

plot(phi_marg_bym, type = 'l', xlab = expression(phi), ylab = expression(pi (phi ~ "|" ~ y)  ))

unlist(inla.zmarginal(phi_marg_bym, silent = TRUE))
```


 #### M-models 
Until now, we have been assuming the hyperparameter controlling for the strength spatial association is constant across the three years. We try to relax this hypothesis by allowing for year-specific hyperparameters, which can be achieved by using a more flexible class of multivariate models, i.e. the M-models [@Mmodels]. 

Consider the scale parameter $\Sigma$, i.e. the marginal variance of the latent effect $z$, and let us define the definite-positive matrix $M$, such that $M \top M = \Sigma$.


Starting with the PCAR model, if we allow the autocorrelation parameter $\rho$ to change over time, we introduce the matrix-valued parameter $R:= \mathrm{diag}(\rho_{2021}, \rho_{2022}, \rho_{2023})$ and the model becomes thus:
\begin{equation}
z \mid \Sigma, R \sim \mathcal{N} \left( 0,
(M^\top \otimes I_n) [(I_p \otimes D) - (R \otimes W)]^{-1}
\right)
\label{eq:MMod_PCAR}
\end{equation}

Where $n=256$ and $p=4$, and the remainder of notation is equal to previous sections.
Since the matrix $M$ has dimension $p^2$ and is not symmetric, modelling it directly would become burdensome. We therefore opt to make directly inference on $\Sigma$. In line with [@vicente2023high], we employ the Bartlett factorisation to $\Sigma$, which briefly means that we set $\Sigma:=BB^\top$, where $B$ is a lower-triangular matrix whose off-diagonal elements are assigned a Normal prior and the squares of its diagonal are assigned a $\chi^2$ distribution. This is equivalent to the assumption that $\Sigma$ follows a Wishart prior; for a proof see e.g. [@Kabe].

As we previously mentioned, we loosely follow the workflow underlying the \texttt{bigDM} R package[@vicente2023high], which implements the M-model formulation of the PCAR, LCAR and BYM models. 

The autoregressive and mixing parameters follow a multivariate and independent PC-prior; for the time being, 
we keep assuming $\pi(\psi \leq \frac{1}{2}) = \frac{2}{3}$, where $\psi$ is a generic hyperparameter. More detail on PC-prior
definition can be found in my PhD thesis or in the notes of the shared overleaf project.

```{r MmodPCAR, message = FALSE, output = FALSE, warning = FALSE, echo = FALSE}
cav_PMMCAR_inla <- inla(
  N_ACC ~  0+ Y_2021 + Y_2022 + Y_2023 + Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.PMMCAR.model(k = 4, W = W_con, df = 6, PC = T)),
  offset = log(nn),
  family = "poisson", data =dd,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)


```


Likewise, we test the LCAR model, which under the M-model formulation features a matrix-valued mixing parameter $\Xi := \mathrm{diag}(\xi_{2021}, \xi_{2022}, \xi_{2023}$

\begin{equation}
z \mid \Sigma, R \sim \mathcal{N} \left( 0,
(M^\top \otimes I_n) [\Xi \otimes (D-W) + (I_p - \Xi) \otimes I_n]^{-1}
\right)
\label{eq:MMod_LCAR}
\end{equation}

```{r MmodLCAR, message = FALSE, output = FALSE, warning = FALSE, echo = FALSE}

cav_LMMCAR_inla  <- inla(
  N_ACC ~ 0+ Y_2021 + Y_2022 + Y_2023 + Y_2024+
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.LMMCAR.model(k = 4, W = W_con,  df = 6, PC = T)),
  offset = log(nn),
  family = "poisson", data =dd, 
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)
```



Lastly, we propose the M-model extension of the BYM.

If we define the matrix-valued mixing parameter$\Phi:=\mathrm{diag}( \phi_1, \phi_2, \dots  \phi_p )$ and $\bar{\Phi}:= \mathrm{diag} ( 1 - \phi_1,  1 - \phi_2 , \dots  1 - \phi_p) = (I_p -  \Phi )$, with $p=3$, the BYM field $\mathbf{Y}$ is given by:


\begin{equation}
\label{eq:Mmod_conv}
Z =  U \Phi^{\frac{1}{2}} M  +  V \bar{\Phi}^{\frac{1}{2}}M
\end{equation}

Where  \begin{itemize}
\item $U = (U_1, U_2, \dots U_p)$ is a multivariate and independent ICAR field, such that $U_j \sim \mathcal{N}_n(0, L^+)$ for $j = 1, 2 \dots p$, and $L^+$ is the pseudoinverse of the scaled graph Laplacian matrix
\item $V = (V_1, V_2, \dots V_p)$ is a collection of $iid$ random Normal vectors, such that $V_j \sim \mathcal{N}_n(0, I_n)$ for $j = 1, 2 \dots p$.
\item $M$ is a generic $p \times p$ full-rank matrix such that $M^\top M = \Sigma$, being $\Sigma$ is the scale parameter. For instance, $M$ can be defined as $D^{1/2} E^\top$, where $D$ is the diagonal matrix of the eigenvalues of $\Sigma$ and $E$ is the corresponding eigenvectors matrix.
\end{itemize}
 
```{r MMod BYM, message = FALSE, output = FALSE, warning = FALSE}
 
cav_MMBYM_inla <- inla(
  N_ACC ~ 0 + Y_2021 + Y_2022 + Y_2023 + Y_2024 +
    TEP_th + ELI + PGR + UIS + ELL + PDI + ER+ 
    f(ID, model = inla.MMBYM.model(k = 4, W = W_con,  PC= T, df = 6) , 
      extraconstr = constr.BYM),
  offset = log(nn), #control.inla = list(h = 1e-5),
  family = "poisson", data =dd,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T, config = T), 
  verbose = F)



```
Model comparison follows:
```{r WAICs table MMod, echo = F, results = "asis", message = FALSE}
WAICS.MMod <- tibble::tibble(
  Model = c("Null", "ICAR", "PCAR", "Leroux", "BYM"),
  WAIC = round(c(
    cav_nosp_inla$waic$waic,  cav_IMCAR_inla$waic$waic,  cav_PMMCAR_inla$waic$waic, 
    cav_LMMCAR_inla$waic$waic, cav_MMBYM_inla$waic$waic),3),
  Eff_params = round(c(
    cav_nosp_inla$waic$p.eff,   cav_IMCAR_inla$waic$p.eff,  cav_PMMCAR_inla$waic$p.eff,
     cav_LMMCAR_inla$waic$p.eff, cav_MMBYM_inla$waic$p.eff),3))

print(xtable::xtable(WAICS.MMod, digits = 3),include.rowname = F)

```


Here we show some posterior summaries for $\alpha$ under the BYM model.

 
```{r alphas MMbym, echo = FALSE, results = "asis", message = FALSE}

betas.MMBYM.inla   <- cav_MMBYM_inla$summary.fixed %>% 
  dplyr::select(.data$mean, .data$sd, .data$`0.025quant`, .data$`0.975quant`) %>%
  dplyr::mutate(Effect = rownames(cav_MBYM_inla$summary.fixed)) %>% 
  dplyr::relocate(.data$Effect, .before = 1) %>%  
  dplyr::rename(Mean = .data$mean, Sd = .data$sd,
                Q_0.025 = .data$`0.025quant`, Q_0.975 = .data$`0.975quant`)

print(xtable::xtable(betas.MMBYM.inla, digits = 3), include.rowname = FALSE)

```


```{r  betas MMBYM plot, echo = FALSE, fig.height = 3, fig.cap = "Posterior marginals of covariate effects, M-model BYM"}

plot.beta.posterior(cav_MMBYM_inla, offset=4)
```

We then show the expected latent effects.

```{r zhat mmbym, echo = FALSE, message = FALSE, warning = FALSE, output = FALSE, fig.cap = "Estimated BYM latent effect using the M-model formulation"}
zhat_plot(cav_MMBYM_inla)
```

We additionally show the fitted values of the counts of accesses, rounded to the closest integer.
```{r yhat mmbym, echo = FALSE, message = FALSE, warning = FALSE, output = FALSE, fig.cap = "Fitted access counts, BYM M-model"}

yhat_plot(cav_MMBYM_inla)

```

Differences with respect to the scalar-mixing model are hardly noticeable in terms of
both $\beta$, $\eta$ and $z$
Lastly, we have a look at the autoregressive (PCAR) and mixing (LCAR, BYM) parameters.


```{r mixing mmod summary, echo = FALSE, results = "asis"}

rho_marg_PMMCAR <- lapply(c(1:4), function(x){
  inla.tmarginal(fun = function(y) {1/(1 + exp(-y))},
                   marginal = cav_PMMCAR_inla$marginals.hyperpar[[x]])
})
  
  
xi_marg_LMMCAR <- lapply(c(1:4), function(x){
  inla.tmarginal(fun = function(y) {1/(1 + exp(-y))},
                   marginal = cav_LMMCAR_inla$marginals.hyperpar[[x]])
})

phi_marg_MMBYM <- lapply(c(1:4), function(x){
  inla.tmarginal(fun = function(y) {1/(1 + exp(-y))},
                   marginal = cav_MMBYM_inla$marginals.hyperpar[[x]])
})

# PCAR autoregressive
rho_marg_PMMCAR_summary <- t(sapply(c(1:4), function(x){
  inla.zmarginal(rho_marg_PMMCAR[[x]], silent = T)
}))

xi_marg_LMMCAR_summary <- t(sapply(c(1:4), function(x){
  inla.zmarginal(xi_marg_LMMCAR[[x]], silent = T)
}))

phi_marg_MMBYM_summary <- t(sapply(c(1:4), function(x){
  inla.zmarginal(phi_marg_MMBYM[[x]], silent = T)
}))
 
marg_hyper_summary <- (rbind(
  rho_marg_PMMCAR_summary, xi_marg_LMMCAR_summary, phi_marg_MMBYM_summary
))

marg_hyper_summary <- as.data.frame(matrix(unlist(marg_hyper_summary[,c(1,2,3,5,7)]), ncol=5, byrow = F))

names(marg_hyper_summary) <- c("Mean", "Sd", "Q0.50", "Q0.025", "Q0.975")
marg_hyper_summary %<>%
  dplyr::mutate(Model = rep(c("PCAR", "LCAR", "BYM"), each = 4)) %>% 
  dplyr::relocate(.data$Model, .before = 1) %>% 
  dplyr::mutate(Year = rep(c("2021", "2022", "2023", "2024"), 3)) %>% 
  dplyr::relocate(.data$Year, .after = .data$Model)
  

print(xtable::xtable(marg_hyper_summary, digits = 3), include.rowname  = F)

```
 
 

Here we plot the marginal posterior of the BYM variance mixing parameter.
 
```{r mixing MMBYM plot, fig.height = 3, fig.cap = "Posterior marginal of the BYM mixing parameters", echo = FALSE}
philimX <- range(0,1)
philimY <- range(do.call(c, lapply(phi_marg_MMBYM, FUN = function(x) x[,2])))

phimarg <- as.data.frame(do.call(cbind, phi_marg_MMBYM))
names(phimarg) <- paste0(rep(c("phi_2021", "phi_2022", "phi_2023", "phi_2024"), each=2), c("__X", "__Y"))


phimarg_long <- tidyr::pivot_longer(phimarg, cols = c(1:ncol(phimarg)),
                                       names_to = c("Year", ".value"),
                                       names_sep = "__")

ggplot2::ggplot(phimarg_long, ggplot2::aes(x = .data$X, y = .data$Y, color = .data$Year)) +
  ggplot2::geom_line(size = 0.7) +
  ggplot2::geom_vline(xintercept = 0)+
  ggplot2::coord_cartesian(xlim = philimX, ylim = philimY) +
  ggplot2::labs(
    title = "Posterior Marginals of mixing parameters",
    x = expression(phi),
    y = expression(pi(phi ~ "|" ~ y)),
    color = "Year") +
  ggplot2::theme_classic()
```

The interpretation is that while spatial association is moderate in 2021 data, the spatial distribution of 2023 data is dominated by noise; 2022 and 2024 data instead display a rather strong spatial association. For 2023 data, the PC prior penalises indeed the departure from the nonspatial model quite strongly.


#### Appendix: sparse parametrisation of the BYM

Recall the BYM as defined in equation \ref{eq:Mmod_conv}; the prior variance of $Z$ is:
$$
\mathrm{Var}\left[ \mathrm{vec}(Z) \mid \Sigma, \Phi \right] = 
\left( M^\top \otimes I_n\right) 
\mathrm{diag}\left(S_1,\ldots,S_p\right)
\left( M \otimes I_n \right)
$$
Where each diagonal block $S_j$ is the variance of $U_j \Phi + V_j \bar{\Phi}$, i.e. $S_j = \phi_j L^+ + (1-\phi_j) I_n$. 



Extending the approach of [@BYM2] to the multivariate case, we know that:

$$
\mathbb{E} [\mathrm{vec}(Z) \mid U, \Phi , \Sigma] = \mathrm{vec}(U \Phi^{\frac{1}{2}}M) =
[( M^{\top}\Phi^{\frac{1}{2}}) \otimes I_n] \mathrm{vec}(U)
$$

and similarly

$$
\mathrm{Var} [\mathrm{vec}(Z) \mid  U, \Phi , \Sigma] =
\left[( M^{\top} \bar{\Phi}^{\frac{1}{2}}) \otimes I_n \right] 
\mathbb{E} \left[
\mathrm{vec}(V)
\mathrm{vec}(V)^\top \right]
\left[(\bar{\Phi}^{\frac{1}{2}} M) \otimes I_n \right] = 
\left(
 M^\top \bar{\Phi}  M \right) \otimes I_n
$$


The distribution of $Z \mid U, \Sigma, \Phi$ then reads:
\begin{align*}
-2 \ln \pi \left(\mathrm{vec}(Z) \mid U, \Sigma, \phi \right) 
%
\mathrm{vec}(Z)^{\top}
\left[ \left(
 M^{-1} \bar{\Phi}^{-1}{M^{-1}}^\top
\right) \otimes I_n \right] 
\mathrm{vec}(Z) \\ 
%
- 2\mathrm{vec}(Z)^{\top} 
\left[ \left( 
 M^{-1} \bar{\Phi}^{-1}{M^{-1}}^\top\right) \otimes I_n \right] 
\left[ \left( M^\top \Phi^{\frac{1}{2}} \right) \otimes I_n \right] \,\mathrm{vec}(U)   \\
%
+  \mathrm{vec}(U)^{\top}
    \left[ \left(\Phi^{\frac{1}{2}} M \right) \otimes I_n \right]
    \left[ \left(  M^{-1} \bar{\Phi}^{-1}{M^{-1}}^\top\right) \otimes I_n \right]
    \left[ (M^\top\Phi^{\frac{1}{2}} ) \otimes I_n \right]
   \mathrm{vec}(U) \\
%
= C + \mathrm{vec}(Z)^{\top}
\left[ \left(
 M^{-1} \bar{\Phi}^{-1}{M^{-1}}^\top
\right) \otimes I_n \right] 
\mathrm{vec}(Z) \\ 
%
- 2\mathrm{vec}(Z)^{\top} 
\left[ \left(  M^{-1} \bar{\Phi}^{-1} \Phi^{\frac{1}{2}} M^{\top} \right)
\otimes I_n \right]  \,\mathrm{vec}(U)   \\
%
+  \mathrm{vec}(U)^{\top}
    \left[ \left(  \Phi  \bar{\Phi}^{-1}  \right) \otimes I_n \right]
   \mathrm{vec}(U)
\end{align*}

Now, for brevity let us define the following $p \times p$ matrices:
\begin{align*}
q_{11} :=  M^{-1} \bar{\Phi}^{-1}{M^{-1}}^\top; \quad
q_{12} :=  M^{-1} \bar{\Phi}^{-1} \Phi^{\frac{1}{2}}; \quad
q_{22} := \Phi \bar{\Phi}^{-1}
\end{align*}
Hence 
\begin{align*}
-2 \ln \pi \left(\mathrm{vec}(Z) \mid U, \Sigma, \Phi \right) 
= C + \mathrm{vec}(Z)^{\top}
\left(q_{11} \otimes I_n \right) 
\mathrm{vec}(Z) \\
%
- 2\mathrm{vec}(Z)^{\top} 
\left(  q_{12} \otimes I_n \right)  \,\mathrm{vec}(U)\\
%
+  \mathrm{vec}(U)^{\top}
    \left(q_{22} \otimes I_n \right)
   \mathrm{vec}(U)
\end{align*}
Then, we have 
\begin{align*}
-2 \ln \pi \left(\mathrm{vec}(Z), \mathrm{vec}(U) \mid \Sigma, \phi \right)  
= C + \mathrm{vec}(Z)^{\top}
\left(q_{11} \otimes I_n \right) 
\mathrm{vec}(Z)\\ 
%
- 2\mathrm{vec}(Z)^{\top} 
\left(  q_{12} \otimes I_n \right)  \,\mathrm{vec}(U)\\  
%
+  \mathrm{vec}(U)^{\top}
    \left(q_{12} \otimes I_n + I_p \otimes L\right)
   \mathrm{vec}(U)
\end{align*}
Hence, with some straightforward algebra, it can be concluded that:
\begin{equation} \label{eq:joint_bym_mmod}
    \begin{pmatrix}
        \mathrm{vec} (Z) \\ \mathrm{vec} (U) 
    \end{pmatrix}
    \sim \mathcal{N}_{2np} \left( 0, \begin{pmatrix}
            q_{11} \otimes I_n \, & 
            \, - q_{12} \otimes I_n \\
            - q_{12}^\top\otimes I_n \, & \,
             q_{22} \otimes I_n + I_p \otimes L
        \end{pmatrix}^{-1} \right)
\end{equation}
Which generalises to the multivariate case the sparse precision derived by [@BYM2]. 





---
title: "Explorative analysis of accesses to support centers for gender-based violence
  in Apulia"
output:
  #         To make this file work with pdf output, it is
  #         necessary to switch hyperreferences style
  #         from [text](link) to \href{link}{text}.
  #         At the moment, hyperrefs are at two github links,
  #         so they can be detected across this script by
  #         searching for 'github' in the finder bar to spawn with CTRL+F
  html_document:
    df_print: paged
  pdf_document: default
  # WARNING: this file does not compile to pdf
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(sf)
```

```{r input, echo = FALSE, message = FALSE, warning = FALSE, output = FALSE}
load("input/CAV_input_mun_2022.RData")

#' 2022 municipalities shapefiles; easily obtainable by scraping with the following 
#' commented code:
#' Mun22_shp <- SchoolDataIT::Get_Shapefile(2022)
#' Shp <- Mun22_shp %>% dplyr::filter(.data$COD_REG == 16) %>% 
#'  dplyr::select(.data$COD_PROV, .data$PRO_COM, .data$COMUNE)
#'
#' Still, we leave the static shapefile in order NOT to need internet connection:
load("input/Shp.RData")

# Function to extract numeric digits from a strings vector (needed to filter age):
nn_extract <- function(string){
  nn <- gregexpr("([0-9])", string)
  ls.out <- regmatches(as.list(string), nn)
  res <- unlist(lapply(ls.out, function(x) as.numeric(paste(x, collapse = ""))))  
  return(res)
}

# Female population aged >= 15 years.
# Source data: http://dati.istat.it/Index.aspx?DataSetCode=DCIS_POPRES1#
Popolazione_Puglia_2022 <- readr::read_csv("input/Popolazione_Puglia_2022.csv") %>% 
  dplyr::select(.data$ITTER107, .data$Territorio, .data$SEXISTAT1, .data$ETA1, .data$Value) %>% 
  dplyr::filter(.data$ETA1 != "TOTAL") %>% 
  dplyr::mutate(ETA1 = nn_extract(ETA1)) %>% 
  dplyr::mutate(ITTER107 = as.numeric(ITTER107))
names(Popolazione_Puglia_2022) <- c("PRO_COM", "Comune", "Sesso", "Eta", "Popolazione")

# Filter and aggregate:
Pop_f_15 <- Popolazione_Puglia_2022 %>% dplyr::filter(.data$Sesso == 2) %>% 
  dplyr::filter(.data$Eta > 14) %>% 
  dplyr::group_by(.data$PRO_COM, .data$Comune) %>% 
  dplyr::summarise(nn = sum(.data$Popolazione)) %>% dplyr::ungroup()

# Complete dataset:
dd <- Shp %>% dplyr::left_join(Pop_f_15[,c(1,3)],
                               by = "PRO_COM") %>% 
  dplyr::left_join(dplyr::select(CAV_mun_22, -.data$comune),by = "PRO_COM") %>% 
  dplyr::left_join(dplyr::select(Indicators, -.data$Comune), by = "PRO_COM")

# Municipalities from which no woman reported violence --> count == 0
dd$N_ACC[is.na(dd$N_ACC)] <- 0 
# "access ratio"
dd$F_ACC <- dd$N_ACC/dd$nn

munWcav <- munWcav <- c (71020,71024,71051,72004,72006,72011,72014,
                         72019,72021,72029,72031,72033,72035,73013,
                         73027,74001,74009,75018,75029,75035,75059,
                         110001,110002,110009)

# Tremiti Islands are a singleton --> need to remove them
# in order to perform spatial analysis
suppressWarnings({
  singletons <- which(unlist(lapply(spdep::poly2nb(dd), function(x) x[1L] == 0)))
})


# Filter out singletons
dd_con <- dd[-singletons, ]

load("input/dists_th_22.RData")

# This is the dataset we will concretely work on:
dd_con <- dd_con %>% 
  dplyr::left_join(dists_th_22, by = "PRO_COM") %>% 
  dplyr::mutate(TEP_th_22 = as.vector(scale(.data$TEP_th_22)))  %>% 
  dplyr::mutate(AES = as.vector(scale(.data$AES))) %>% 
  dplyr::mutate(MFI = as.vector(scale(.data$MFI)))  %>% 
  dplyr::mutate(PDI = as.vector(scale(.data$PDI)))  %>% 
  dplyr::mutate(ELL = as.vector(scale(.data$ELL)))  %>% 
  dplyr::mutate(ER = as.vector(scale(.data$ER)))  %>% 
  dplyr::mutate(PGR = as.vector(scale(.data$PGR)))  %>% 
  dplyr::mutate(UIS = as.vector(scale(.data$UIS)))  %>% 
  dplyr::mutate(ELI = as.vector(scale(.data$ELI))) 

# sd of travel time: almost 16 minutes
#attr(scale(dists_th_22$TEP_th_22), "scaled:scale")

# neighbours list
nb_con <- spdep::poly2nb(dd_con)
# neighbouring/adjacency matrix
W_con <- spdep::nb2mat(nb_con, style = "B")
rownames(W_con) <- colnames(W_con) <- dd_con$PRO_COM
Lapl_con <- diag(rowSums(W_con)) - W_con
V_con <- eigen(Lapl_con)$vectors
# row ID - needed for spatial models
dd_con$ID <- c(1:nrow(dd_con))

# Full GLM --> for model matrix
glm_all_X <- glm(N_ACC ~ 1 + TEP_th_22 + MFI + AES + PDI + ELL + ER +
                   PGR + UIS + ELI + offset(log(nn)),
                 data = dd_con, family = "poisson")
# model matrix
X <- model.matrix(glm_all_X)


```


## Data
The dataset employed regards the counts of accesses to gender-based violence support centers in the Apulia region by residence municipality of the women victims of violence during 2022. `R` codes to generate the dataset are in the R script [posted here](https://github.com/lcef97/CAV_Puglia/blob/main/CAV_2022.R) which this report is based on.

Here, we only take into account the violence reports which support centers actually take charge of, at the risk of underestimating the counts of gender-based violence cases.
This choice is driven by the need of avoiding duplicated records, since e.g. it may happen that a support center redirects a victim to another support center. 

In order to avoid singletons in the spatial structure of the dataset, we removed the Tremiti Islands from the list of municipalities included ($0$ accesses to support centers in 2022).

Therefore, the municipality-level dataset in scope consists of $256$ observations. 

We can only take into account the accesses to support centers for which the origin municipality of victims is reported. Therefore, the total count of accesses in scope is $2259$. Among these accesses, $1516$ were taken charge of. 

Here, we plot the log-access rate per residence municipality, i.e. the logarithm of the ratio between access counts and female population. Blank areas correspond to municipalities from which zero women accessed support centers ($82$ municipalities).


```{r Accesses plot, echo = FALSE, warning = FALSE, message = FALSE, fig.height = 3}
dd_con %>% 
  dplyr::mutate(rate = log(.data$N_ACC) - log(.data$nn)) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(ggplot2::aes(fill = .data$rate))+
  ggplot2::labs("Log incidence ratio") +
  ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1) +
  ggplot2::theme_classic()
  

```

## Covariates

Our target is explaining the number of accesses to support centers, $y$, defined at the municipality level, on the basis of a set of candidate known variables.

We model $y$ via a simple Poisson GLM.

We have at disposal a number of candidate explanatory variables, which include the distance of a municipality from the closest support center and a set of variables measuring social vulnerability under different dimensions; these latter covariates are provided by the ISTAT.A more detailed description of these covariates is in [this excel metadata file](https://github.com/lcef97/CAV_Puglia/blob/main/Metadata/Indice_composito_fragilita_PUGLIA_2021.xlsx).

All covariates are scaled to have null mean and unit variance.

<!-- :::{.only-html} -->
  -  $\mathrm{TEP}$, i.e. the distance of each municipality from the closest municipality hosting a support center. Distance is measured by road travel time in minutes (acronym TEP stays for Tempo Effettivo di Percorrenza, i.e. Actual Travel Time).
  
For instance, the support center designated for the municipality of Adelfia (province of Bari, $3$rd municipality in the dataset) is located in Capurso (BA). Then, $\mathrm{TEP}_{3}$ denotes the travel time between Adelfia and Capurso ($17$ minutes). 

  -  $\mathrm{AES}$, the distance from the closest infrastructural pole, always measured in travel time.
  -  $\mathrm{MFI}$, i.e. the decile of municipality vulnerability index.
  -  $\mathrm{PDI}$, i.e. the dependency index, i.e. population either $\leq 20$ or $\geq 65$ years over population in $[20 - 64]$ years.
  -  $\mathrm{ELL}$, i.e. the proportion of people aged $[25-54]$ with low education.
  -  $\mathrm{ERR}$, i.e. employment rate among people aged $[20-64]$.
  -  $\mathrm{PGR}$, i.e. population growth rate with respect to 2011.
  -  $\mathrm{UIS}$, i.e. the ventile of the density of local units of industry and services (where density is defined as the ratio between the counts of industrial units and population).
  -  $\mathrm{ELI}$, i.e. the ventile of employees in low productivity local units by sector for industry and services.

<!--  ::: -->




First, we visualise the correlations among these explanatory variables:


```{r correls, echo = F, warning = F, fig.height = 3}
ggplot2::ggplot(data = reshape2::melt(cor(X[,-1]))) +
  ggplot2::geom_tile(ggplot2::aes(
    x = .data$Var2, y = .data$Var1, fill = .data$value), color = "black", size = 3) +
  ggplot2::geom_text(ggplot2::aes(
    x = .data$Var2, y = .data$Var1, label = round(.data$value, 2))) +
  ggplot2::scale_fill_gradient2(
    low = "blue", mid = "white", high = "red", midpoint = 0) +
  ggplot2::theme_minimal()
```


Then, we implement a very simple forward selection algorithm. At each iteration, we add to the model the covariate allowing for the lowest BIC, until adding an additional covariate does not allow to reduce it anymore:

We see the correlation between the two distances is very high ($0.72$), and so is the correlation between the fragility index decile and the density of productive units. 

In the first case, we drop the distance from the nearest infrastructural pole We do so because, if taken alone, the distance from the closest support center appears a slightly better predictor, using the Schwarz information criterion (or, indifferently, the Akaike Information Criterion):
```{r BICS single covar}

stats::BIC(glm(N_ACC ~ 1 + AES, family = "poisson",
               offset = log(nn), data = dd_con))

stats::BIC(glm(N_ACC ~ 1 + TEP_th_22, family = "poisson",
               offset = log(nn), data = dd_con))

```

We should do the same for the other couple of variables but since `MFI` is a combination of all covariate except for `TEP_th`, we will drop the synthetic indicator and leave the remainder.

```{r forward selection, warnings = F}
covariates <- colnames(X)[-c(1, which(colnames(X) %in% c("AES", "MFI")))]
# Covariates included:
covs.in <- c()
# Covariates not included:
BIC.min <- c()
while(length(covs.in) < length(covariates)){
  covs.out <- covariates[which(!covariates %in% covs.in)]

  BICs <- c()
  # At each iteration, we add one of the remaining covariates
  for(j in c(1:length(covs.out))) {
    formula.temp <- paste0("N_ACC ~ 1 + offset(log(nn)) +", 
                           paste(covs.in, collapse = "+"),
                           "+", covs.out[j])
    mod.tmp <- glm(formula.temp, data = dd_con, family = "poisson")
    BICs[j] <- stats::BIC(mod.tmp)
  }
  # Covariate allowing for the best model is added:
  BIC.min <- c(BIC.min, min(BICs))
  covs.in <- c(covs.in, covs.out[which.min(BICs)])
}
```


```{r misc old code, eval = FALSE, echo = FALSE}
  #BIC.min <- c(BIC.min, min(BICs))
  #if(length(BIC.min)>1 && BIC.min[length(BIC.min)] >= BIC.min[length(BIC.min)-1]){
  #  break
  #} else{
    #covs.in <- c(covs.in, covs.out[which.min(BICs)])
  #}
```


The optimal number of covariates (covariates in the model with minimum BIC) is four:
```{r num covars}
covs.in[c(1:which.min(BIC.min))]
```

However, a model with up to $4$ covariates would have all significant regression coefficients:

```{r glm five covs}
summary(glm(
  as.formula(paste0("N_ACC ~ 1 +", paste(covs.in[c(1:5)], collapse = " + "))),
  family = "poisson",offset = log(nn), data = dd_con))$coefficients
```
  - The distance from the closest support center seems to play the key role. The easiest interpretation is that the physical distance represents a barrier to violence reporting. This is quite intuitive if we think of the material dynamics of reporting gender-based violence: one could reasonably expect violent men to prevent their partners to come out and report the violence suffered.
  - The asociation with population growth rate is harder to interpret. This association is most likely influenced by several demographic instrumental variables we are not keeping into account and would indeed deserve a more dedicated focus.
  - The density of production units can be hither considered as a proxy for economic development. The most naive interpretation wuld be that in underdeveloped areas reporting gender violence is somewhat harder than in developed ones.
  - The association with the proportion of people with low educational level appears lower. However, the interpretation seems quite easy: cultural development, in general, would encourage reporting violence. Still, let us remind that $\beta_\mathrm{ELL}$ is in $\mathcal{\Theta}(10^{-2})$.
  - The interpretation of $\beta_{ELI}$ should, intuitively, be similar to $\beta_{UIS}$. We have kept both variables due to their correlation not being particularly high.


With more covariates, no additional valuable association can be found. 
 

In the remainder of this work, we will focus on the two covariates $d, \mathrm{PGR}, \mathrm{ELI}, \mathrm{UIS}$

## Nonspatial regression

We regress the counts of accesses $y$ to support centers on the distance from the former. Both covariates are scaled to zero mean an unit variance. 

\begin{equation}
y_i \mid \eta_i \sim \mathrm{Poisson}(e^{\eta_i - P_i}) \quad \text{where} \quad
\eta_i = \beta_0 + \beta_\mathrm{TEP} \mathrm{TEP}_i + \beta_{PGR} \mathrm{PGR}_i
          + \beta_{ELI} \mathrm{ELI}_i + \beta_{UIS} \mathrm{UIS}_i
\label{eq:glm}
\end{equation}

Where $P_i$ is the female population aged $\geq 15$ in municipality $i$.

```{r glm, echo = FALSE}
cav_glm <- glm(N_ACC ~ 1 + TEP_th_22 + ELI + PGR + UIS, family = "poisson",
                offset = log(nn), data = dd_con)

summary(cav_glm)
```



How do we interpret the regression coefficients? Keeping in mind we are working on the logarithm of the access rate, the standard deviation of the distance, expressed in minutes, is:
```{r SDs of X}
# Distance from closest support center
attr(scale(dists_th_22$TEP_th_22), "scaled:scale")
```


Hence e.g. each $14'6''$ of distance of the a given municipality from the closest support center are associated with a decrease of $0.399$ units in the log-frequency at which women from that municipality access to support centers.

## Spatial regression

We plot the log-residuals $\varepsilon$ of the regression model in equation \ref{eq:glm}, defined as $\varepsilon := \ln y_i - \ln P_i - \ln \hat{y}_i$ being $\hat{y}_i$ the fitted value.


```{r glm residuals, echo = FALSE, fig.height = 3, fig.cap = "Log-residuals of glm regression using theorical distance as explanatory variable"}


resids_glm_th <- log(dd_con$N_ACC) - log(cav_glm$fitted.values) - log(dd_con$nn)

dd_con %>% 
  dplyr::mutate(log_resids = resids_glm_th) %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(ggplot2::aes(fill = .data$log_resids))+
  ggplot2::labs("blank") +
  ggplot2::scale_fill_viridis_c(na.value = "white", direction = -1) +
  ggplot2::theme_classic()

#' Problem: cannot apply Moran test to infinite values!
#' Hence we need to only test autocorrelation across nonzero records.
#' This strongly limits the relevance of the test, if I have a better idea I'll implememnt it.
nonzero <- which(dd_con$N_ACC > 0)

spdep::set.ZeroPolicyOption(TRUE)
suppressWarnings(nb_nonzero <- spdep::poly2nb(dd_con[nonzero, ]))

nonzero_singletons <- which(unlist(lapply(nb_nonzero, function(X) X[1L]==0)))
nonzero_con <- nonzero[-nonzero_singletons]
nb_con_nonzero <- spdep::poly2nb(dd_con[nonzero_con, ])
```

Residuals may exhibit spatial structure. To assess it, we employ the Moran and Geary tests. Since 

Please notice that log-residuals only take finite values across the $175$ municipalities whose female citizens have reported at least one case of violence in 2022.

Additionally, this set of municipalities includes $2$ singletons, which we remove to assess the value of the Moran and Geary statistics. Thus, we have defined the indexes set `nonzero_con` as the set of municipalities from which at least one case of gender-based violence has been reported, *and* which have at least one neighbouring municipalities from which at least one case of gender-based violence was reported. 

```{r moran residuals}
spdep::moran.test(resids_glm_th[nonzero_con],
                  listw = spdep::nb2listw(nb_con_nonzero))
spdep::geary.test(resids_glm_th[nonzero_con],
                  listw = spdep::nb2listw(nb_con_nonzero))

```

In both cases, we find evidence for spatial autocorrelation. However, we must stress out this result does not refer to all the regional territory, but only to a subset of all municipalities ($173$ over $257$)


Based on the autocorrelation evidence, though it has only been assessed for a subset of all municipalities, we try implementing some simple conditional autoregressive models by augmenting the linear predictor


\begin{equation}
\eta_i = \beta_0 + \beta_{d} d_i + \beta_{PGR} \mathrm{PGR}_i
          + \beta_{ELI} \mathrm{ELI}_i + \beta_{UIS} \mathrm{UIS}_i + z_i 
\label{eq:mspat}
\end{equation}

Where $z_i$ represents the latent Gaussian effect. We test three models, all of which have a prior distribution depending on the spatial structure of the underplying graph, in this case the Apulia region. 

We describe the spatial structure starting from municipality neighbourhood, and introduce the neighbourhood matrix $W$, whose generic element $w_{ij}$ takes value $1$ if municipalities $i$ and $j$ are neighbours and $0$ otherwise. For each $i \in [1,n]$, $d_i:= \sum_{j=1}^n w_{ij}$ is the number of neigbours of $i$-th municipality. Plase notice we have have $n = 256$.

For all models, we define $\sigma^2$ as the scale parameter of the latent effect, and in order to avoid overfitting we set a PC-prior on it with rate parameter $\lambda = 1.5$, such that $\mathrm{Prob}(\sigma>\lambda) = 0.01$

Spatial models are computed by approximating the marginal posteriors of interest via the Integrated Nested Laplace Approximation (INLA), adopting the novel Variational Bayes Approach \cite{INLAVB}.

#### ICAR model

The Intrinsic CAR model is the simple formulation among spatial autoregressive models. The conditional distribution of each value $z_i \mid z_{-i}$ is:

\begin{equation}
z_i \mid z_{-i} \sim N \left( \sum_{j=1}^n \frac{w_{ij}}{d_i} z_j \,, \frac{\sigma^2}{d_i}\right)
\label{eq:icar_loc}
\end{equation}
The remainder of the model follows the same notation as eq. \ref{eq:glm}.



```{r inla nosp, echo = FALSE, message = FALSE, warning = FALSE}

library(INLA)
cav_nosp_INLA <- inla(
  N_ACC ~ 1 + TEP_th_22 + UIS + PGR + ELI,
  family = "poisson", offset = log(nn), data =dd_con,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T), 
  inla.mode = "classic", control.inla = list(strategy = "laplace"),
  verbose = F)
```



```{r inla mod, echo = FALSE, message = FALSE, warning = FALSE}

cav_icar_INLA <- inla(
  N_ACC ~ 1 + TEP_th_22 + UIS + PGR + ELI + f(ID, model = "besag", graph = W_con,
                         scale.model = T, prior = "pc.prec", param = c(1.5, 0.01)),
  family = "poisson", offset = log(nn), data =dd_con,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T), 
  inla.mode = "classic", control.inla = list(strategy = "laplace"),
  verbose = F) # better
```



#### PCAR model

The intrinsic autoregressive model is relatively simple to interpret and to implement, 
while also requiring the minimum number of additional parameter (either the scale or the precision).


The drawback, however, is that we implicitly assume a deterministic spatial autocorrelation coefficient equal to 1.
When the autocorrelation is weak, setting an ICAR prior may be a form of misspecification.

A generalisation of this model is the PCAR (proper CAR), which introduces an autocorrelation parameter $\alpha$:


\begin{equation}
z_i \mid z_{-i} \sim N \left( \sum_{j=1}^n \alpha \frac{w_{ij}}{d_i} z_j \,, \frac{\sigma^2}{d_i}\right)
\label{eq:pcar_loc}
\end{equation}

The `R` code to implement the PCAR model in `R-INLA` is in Appendix.
```{r pcar definition, echo = FALSE}
inla.rgeneric.PCAR.model <- 
  function (cmd = c("graph", "Q", "mu", "initial", "log.norm.const", 
                                              "log.prior", "quit"), theta = NULL) {
  interpret.theta <- function() {
    alpha <- 1/(1 + exp(-theta[1L])) # alpha modelled in logit scale
    mprec <- sapply(theta[2L], function(x) {
      exp(x)
    })
    PREC <- mprec
    return(list(alpha = alpha, mprec = mprec, PREC = PREC))
  }
  graph <- function() {
    G <- Matrix::Diagonal(nrow(W), 1) + W
    return(G)
  }
  Q <- function() {
    param <- interpret.theta()
    Q <- param$PREC * 
      (Matrix::Diagonal(nrow(W), apply(W, 1, sum)) - param$alpha * W)
    return(Q)
  }
  mu <- function() {
    return(numeric(0))
  }
  log.norm.const <- function() {
    val <- numeric(0)
    return(val)
  }
  log.prior <- function() {
    param <- interpret.theta()
    val <- -theta[1L] - 2 * log(1 + exp(-theta[1L]))
    # # PC prior
    val <- val + log(lambda/2) - theta[2L]/2 - (lambda * exp(-theta[2L]/2))
    # # Gamma(1, 5e-5), default prior:
    #val <- val + dgamma(exp(theta[2L]), shape = 1, rate = 5e-5, log = T) + theta[2L]
    # # Uniform prior on the standard deviation
    #val <- val - sum(theta[2L])/2 - k * log(2)
    return(val)
  }
  initial <- function() {
    return(c(0, 4))
  }
  quit <- function() {
    return(invisible())
  }
  if (as.integer(R.version$major) > 3) {
    if (!length(theta)) 
      theta = initial()
  }
  else {
    if (is.null(theta)) {
      theta <- initial()
    }
  }
  val <- do.call(match.arg(cmd), args = list())
  return(val)
}
PCAR.model <- function(...) INLA::inla.rgeneric.define(inla.rgeneric.PCAR.model, ...)
```

```{r pcar run, message = FALSE, echo = FALSE, output = FALSE}
cav_pcar_INLA<- inla(N_ACC ~ 1 + TEP_th_22 + UIS + PGR + ELI + 
                           f(ID, model = PCAR.model(W = W_con, k = 1, lambda = 1.5)),
                         family = "poisson", offset = log(nn), data =dd_con,
                         num.threads = 1, control.compute = 
                           list(internal.opt = F, cpo = T, waic = T), 
                         #inla.mode = "classic", control.inla = list(strategy = "laplace"),
                         control.predictor = list(compute = T),
                         verbose = T) 


```

We show the posterior summary for the autocorrelation coefficient. It does not appear strong indeed. The credible interval also appears uncannily wide:
```{r alfa, echo = FALSE}
expit <- function (X){
  return(1/(1 + exp(-X)))
}

inla.zmarginal(inla.tmarginal(fun = expit,
                              marginal = cav_pcar_INLA$marginals.hyperpar[[1]]))
```



#### BYM model


Perhaps, our data are generated by a process dominated from noise. We can thus try a different path: the BYM model. On a preliminary stance, we keep trusting in the accuracy of the Laplace approximation and stick to INLA. On a later stage, it would be more rigorous to compare INLA results to the posteriors of a model estimated with MCMC.

The BYM model we employ follows the parametrisation of [@BYM2]:

\begin{equation}
z_i = \sigma \left(\sqrt{\phi} u_i + \sqrt{1-\phi} v_i \right)
\label{eq_bym2}
\end{equation}

where $u$ is an ICAR field, $v$ is an IID standard Gaussian white noise i.e. $v \sim N(0, I)$, and $\phi$ is a mixing parameter $\in [0, 1]$.

```{r INLA bym, echo = FALSE}

cav_bym_INLA <- inla(
  N_ACC ~ 1 + TEP_th_22 + UIS + PGR + ELI + f(ID, model = "bym2", graph = W_con,
                         scale.model = T, prior = "pc.prec", param = c(1.5, 0.01)),
  family = "poisson", offset = log(nn), data =dd_con,
  num.threads = 1, control.compute = list(internal.opt = F, cpo = T, waic = T), 
  #inla.mode = "classic", control.inla = list(strategy = "laplace"),
  verbose = F)
```

#### Leroux model

As an alternative to take into account both structured and unstructured latent effects, we also test the Leroux autoregressive model [@Leroux]. In this case, the local prior for $z_i$ is

\begin{equation}
z_i \mid z_{-i} \sim N \left( \sum_{j=1}^n \frac{\xi}{1 - \xi + \xi d_i} \frac{w_{ij}}{d_i} z_j \,, \frac{\sigma^2}{1 - \xi + \xi d_i}\right)
\label{eq:leroux_loc}
\end{equation}

Where $\xi \in [0, 1]$ is the mixing parameter. A more interesting representation of the Leroux model is the joint prior
$$
z \mid \sigma^2, \xi \sim N(0, \sigma^2[\xi R + (1-\xi)I]^{-1})
$$
where $R := D-W$ is the graph Laplacian matrix, $W$ is the neighbourhood matrix and $D$ is the corresponding degree matrix.


```{r INLA Leroux, echo = FALSE}
cav_leroux_INLA <- inla(N_ACC ~ 1 + TEP_th_22 + PGR + UIS + ELI +
                          f(ID, model = "besagproper2", graph = W_con, 
                            hyper = list(prec = list(prior = "pc.prec", param = c(1.5, 0.01)))),
                     family = "poisson", offset = log(nn), data =dd_con,
                     num.threads = 1, control.compute = 
                       list(internal.opt = F, cpo = T, waic = T), 
                     #inla.mode = "classic", control.inla = list(strategy = "laplace"),
                     control.predictor = list(compute = T),
                     verbose = F) 

```



#### Comparison

We briefly compare these models through the WAIC [@GelmanWAIC]:

```{r WAICs table, echo = F}
WAICS_Poisson <- tibble::tibble(Model = c("ICAR", "PCAR", "BYM", "Leroux"),
           WAIC = round(c(cav_icar_INLA$waic$waic, cav_pcar_INLA$waic$waic, 
                    cav_bym_INLA$waic$waic, cav_leroux_INLA$waic$waic),3),
           Eff_Params = round(c(cav_icar_INLA$waic$p.eff, cav_pcar_INLA$waic$p.eff, 
                    cav_bym_INLA$waic$p.eff, cav_leroux_INLA$waic$p.eff),3))

WAICS_Poisson

```
As we can see, models taking into account random noise have a better performance. Please notice the effective number of parameters, i.e. the number of *unconstrained* parameters is higher in the ICAR than in the BYM and Leroux models, even though these require an additional parameter.

We show the postetior summary of covariates effects under the BYM model. There are no noteworthy differences with other models in terms of covariate effects estimation.

```{r BYM fixed, echo = FALSE}
round(cav_bym_INLA$summary.fixed, 3)
```


The interpretation the posteriors of $\beta$ under this spatial model is not exactly the same as for the GLM. As we see, while the distance from the closest support center remains a strong predictor, the two economic variables seem to lose their significance; this is mainly due to variance inflation. The population growth rate still has a significant association instead.

Now, there are two ways we can refine spatial regression:
  - Try to remove the spatial structure from covariates, at least from `UIS` and `ELI`, e.g. by leveraging on the spectral properties of the underlying graph. To do so, we rely on the innovative methodology of [@Urdangarin].
  
  Here, we do **not** mean to affect `TEP_th_22`, but only the other three covariates; this because the spatial pattern in a distance indicator should not, in my view, be removed from a regression model
  
  - Drop those two covariates directly and only keep `TEP_th_22` and `ELI`


We show the `R` code for the first alternative approach, i.e. removing spatial trends from covariates. Considering we have $256$ sites, we remove the last $13$ non-constant eigenvectors ($5 \%$ of the total)

```{r INLA deconfound}
deconfound <- function(X, Lapl = Lapl_con, n.eigen.out){
  X <- as.matrix(X)
  V <- eigen(Lapl)$vectors
  rk <- Matrix::rankMatrix(Lapl)
  coef <- solve(V, X)
  eigen.in <- c(1:(rk-n.eigen.out), c((rk+1):ncol(V)))
  X_nosp <- V[, eigen.in] %*% coef[eigen.in, ]
  return(X_nosp)
}
```

```{r INLA bym spatplus, echo = FALSE}


dd_con_nosp <- dd_con %>%
  dplyr::mutate(PGR  = deconfound(.data$PGR, n.eigen.out=13)) %>% 
  dplyr::mutate(ELI  = deconfound(.data$ELI, n.eigen.out=13)) %>% 
  dplyr::mutate(UIS  = deconfound(.data$UIS, n.eigen.out=13))


cav_bym_INLA_spatplus <- inla(N_ACC ~ 1 + TEP_th_22 + PGR + UIS + ELI +
                       f(ID, model = "bym2", graph = W_con,  scale.model = T, 
                         hyper = list(prec = list(prior = "pc.prec", param = c(1.5, 0.01)))),
                     family = "poisson", offset = log(nn), data = dd_con_nosp,
                     num.threads = 1, control.compute = 
                       list(internal.opt = F, cpo = T, waic = T), 
                     #inla.mode = "classic", control.inla = list(strategy = "laplace"),
                     control.predictor = list(compute = T),
                     verbose = F)
```

Estimated covariate effects are shown

```{r bym spatplus fixed, echo = FALSE}

round(cav_bym_INLA_spatplus$summary.fixed, 3)
```

As we see, removing the spatial patterns from covariates does not "move" credibility interval of`UIS` and`ELI` from zero. In this particular application, we deem deconfounding covariates of scarce interest. 

If, instead, we remove the non-significant covariates, this would be the result:

```{r INLA bym less covs, echo = FALSE}

cav_bym_INLA_2covs <- inla(N_ACC ~ 1 + TEP_th_22 + PGR +
                       f(ID, model = "bym2", graph = W_con,  scale.model = T, 
                         hyper = list(prec = list(prior = "pc.prec", param = c(1.5, 0.01)))),
                     family = "poisson", offset = log(nn), data = dd_con,
                     num.threads = 1, control.compute = 
                       list(internal.opt = F, cpo = T, waic = T), 
                     #inla.mode = "classic", control.inla = list(strategy = "laplace"),
                     control.predictor = list(compute = T),
                     verbose = F)
round(cav_bym_INLA_2covs$summary.fixed, 3)

```

And an improved WAIC. Please notice the decrease in WAIC is higher than the decrease in free parameters, hence the improvement must also be attributed to improved fitting.
```{r INLA less covs waic}
cav_bym_INLA_2covs$waic$waic
cav_bym_INLA_2covs$waic$p.eff
```

This model may bring to interesting results. We can also notice a change in the mixing parameter:
```{r hyperpar bym}
# Model with four covariates ("full" one)
round(cav_bym_INLA$summary.hyperpar,3)
# Model with two covariates ("reduced" one)
round(cav_bym_INLA_2covs$summary.hyperpar,3)

```

## Further developments: zero-inflated regression

The number of zero counts is high:
```{r zero counts}
sum(dd_con$N_ACC == 0)
barplot(table(dd_con$N_ACC))
```

We may wonder if the data generating process incorporates a zero-generating component. We can model this augmented process through zero-inflated Poisson likelihood:
$$
p(y_i | \eta_i) = \pi_0 \mathbb{I}{ \lbrace y_i=0 \rbrace } + (1-\pi_0) 
\mathbb{I}{ \lbrace y_i>0 \rbrace }
\frac{e^{-e^{\eta_i - P_i} - \eta_i y_i}}{y_i!}
$$
Where $\pi_0 := \mathrm{Prob} \lbrace y_i = 0 \rbrace$ for all $i$. The remainder of the notation is akin to the nonspatial regression section. 

We estimate the ZIP model maintaining the BYM latent effect inside $\eta$:

```{r ZIP bym inla, echo = FALSE, output = FALSE, message = FALSE}
cav_bym_zip_INLA <- inla(N_ACC ~ 1 + TEP_th_22 + PGR + UIS + ELI +
                       f(ID, model = "bym2", graph = W_con,  scale.model = T, 
                         hyper = list(prec = list(prior = "pc.prec", param = c(1.5, 0.01)))),
                     family = "zeroinflatedpoisson1", offset = log(nn), data =dd_con,
                     num.threads = 1, control.compute = 
                       list(internal.opt = F, cpo = T, waic = T), 
                     #inla.mode = "classic", control.inla = list(strategy = "laplace"),
                     control.predictor = list(compute = T),
                     verbose = F) 

```

And show the corresponding summaries:
```{r}
summary(cav_bym_zip_INLA)
```

Estimates for $\pi_0$ are low, with mean and median $\approx 0.05$. The mixing parameter is highly shrunk with respect to the non-inflated regression model. The latent component in $\eta$ is thus dominated by random noise.

It is, however, worth noticing how INLA manages to meet the regularity conditions to approximate the CPO more often than in the non-inflated model. Still, CPO must be re-computed manually before employing it as an evaluation metrics:
```{r cpo failures}

sum(cav_bym_INLA$cpo$failure)
sum(cav_bym_INLA$cpo$failure > 0)


sum(cav_bym_zip_INLA$cpo$failure)
sum(cav_bym_zip_INLA$cpo$failure > 0)
```
The reason for failures in meeting the regularity conditions to compute the CPO within INLA would deserve more attention. A preliminary guess would be that the likelihood is strongly skewed with a small sample size. Perhaps. 
 
## Weakness elements and possible developments

From this preliminary analysis, inference on spatial models is hindered by the dominance of random noise over structured spatial effects. This can be argued from the posterior distribution of the mixing parameter in the BYM model, other than from the low spatial autocorrelation parameter in the PCAR.

This means that only to a small extent the variation in $y$ not explained by covariates can be explained by spatial structure.

On the other hand, it is difficult to assert *all* variation not explained by covariates is pure noise, otherwise we would have evidence for the lack of autocorrelation in residuals. We tested the hypothesis of no autocorrelation in GLM residuals by the Moran's $I$ test, but in doing so we had to only test the residuals of areas with nonzero counts.

Moreover, spatial models are estimated using the INLA. While this is a broadly employed approach in epidemiology and in disease mapping, so far we did not assess how accurate the Laplace approximation has been.

To do so, we should e.g. rerun the same models using MCMC methods, e.g. using  `R` libraries such as `CARBayes`, and replicating the same prior structure used.

Lastly, we did *not* model the rate at which gender violence occurs, but the occurrence of violence reports. Higher occurrence of violence reports from a given territory may thus depend on two factors: either the higher occurrence of violence in that territory, or the ease in reporting violence for the residents. 

Whereas the easiest interpretation is that violence occurrence is underestimated in low-reporting areas, at the time being nothing prevents us from suspecting that the placement of support centers is at least partially strategic, i.e. the distribution of supporting centers is more dense in areas in which violence occurs, for some reason we don't know, aa a higher frequence. 

## Appendix: the WAIC

Following \cite{GelmanWAIC}, the WAIC is given by the sum of two components:

$$
WAIC := 2 \sum_{i=1}^n \mathrm{VAR}[\ln p(y_i |\theta)]
- 2 \sum_{j=1}^n \ln \mathbb{E}[p(y_i | \theta)]
$$
Where $\theta$ is the full set of model parameters; the variance and the average are computed by integrating over the posterior of $\theta$.
The first addendum denotes the number of free parameters, while the second term is a measure for goodness of fit. 

## Appendix: R code to implement the PCAR model in `INLA`

Although it is not readily implemented in `R-INLA` (the `"besagproper"` effect is actually the Leroux model) we may base the R code on the `INLAMSM`` package [@INLAMSM]:
```{r pcar display code, eval = FALSE}
inla.rgeneric.PCAR.model <- 
  function (cmd = c("graph", "Q", "mu", "initial", "log.norm.const", 
                                              "log.prior", "quit"), theta = NULL) {
  interpret.theta <- function() {
    alpha <- 1/(1 + exp(-theta[1L])) # alpha modelled in logit scale
    mprec <- sapply(theta[2L], function(x) {
      exp(x)
    })
    PREC <- mprec
    return(list(alpha = alpha, mprec = mprec, PREC = PREC))
  }
  graph <- function() {
    G <- Matrix::Diagonal(nrow(W), 1) + W
    return(G)
  }
  Q <- function() {
    param <- interpret.theta()
    Q <- param$PREC * 
      (Matrix::Diagonal(nrow(W), apply(W, 1, sum)) - param$alpha * W)
    return(Q)
  }
  mu <- function() {
    return(numeric(0))
  }
  log.norm.const <- function() {
    val <- numeric(0)
    return(val)
  }
  log.prior <- function() {
    param <- interpret.theta()
    val <- -theta[1L] - 2 * log(1 + exp(-theta[1L]))
    # # PC prior
    val <- val + log(lambda/2) - theta[2L]/2 - (lambda * exp(-theta[2L]/2))
    # # Gamma(1, 5e-5), default prior:
    #val <- val + dgamma(exp(theta[2L]), shape = 1, rate = 5e-5, log = T) + theta[2L]
    # # Uniform prior on the standard deviation
    #val <- val - sum(theta[2L])/2 - k * log(2)
    return(val)
  }
  initial <- function() {
    return(c(0, 4))
  }
  quit <- function() {
    return(invisible())
  }
  if (as.integer(R.version$major) > 3) {
    if (!length(theta)) 
      theta = initial()
  }
  else {
    if (is.null(theta)) {
      theta <- initial()
    }
  }
  val <- do.call(match.arg(cmd), args = list())
  return(val)
  }

PCAR.model <- function(...) INLA::inla.rgeneric.define(inla.rgeneric.PCAR.model, ...)
```


## Bibliography





